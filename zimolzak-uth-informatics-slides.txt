---
title: Machine Learning to Enhance Electronic Detection of Diagnostic Errors
author: Andrew Zimolzak, MD, MMSc
institute:
- Department of Medicine, Section of Health Services Research
- Baylor College of Medicine
- Michael E.\ DeBakey VA Medical Center
date: November 19, 2025
theme: Goettingen
fonttheme: structurebold
colortheme: whale
aspectratio: 149
---

# Introduction

## Background: EHRs to study medical error

Management errors are often what springs to mind when discussing
medical error.

- *E.g.,* many studies of adverse drug events[^classen] and medication
errors[^bates]^,^[^koppelRole]

- Or "retract and reorder" as a signal of
wrong-patient electronic orders.[^mgt]^,^[^rapid]

- But what if the treatment, *etc.* is ordered correctly, but the
  **diagnosis** was wrong?

[^classen]: Classen *et al. JAMA.* 1991;266(20):2847--2851.

[^koppelRole]: Koppel *et al. JAMA.* 2005;293(10):1197--1203.

[^bates]: Bates *et al. JAMA.* 1998;280(15):1311--1316.

[^rapid]: Koppel *et al. JAMIA.* 2008;15(4):461--465.

[^mgt]: Adelman *et al. JAMIA.* 2012;20(2):305--310.


## The diagnostic process[^national]

![diagnostic process](img/dxprocess.png)\

[^national]: National Academies of Sciences, Engineering, and Medicine
2015. *Improving Diagnosis in Health Care.* Washington, DC: The
National Academies Press. https://doi.org/10.17226/21794.


## To study diagnostic error, first we must find it.

Diagnostic errors cause substantial patient harm, but
monitoring strategies are underdeveloped.[^national]

E-triggers:
: Rules-based algorithms using EHR data to flag possible **missed
opportunities in diagnosis** (MODs)

Example:[^trigExample]

- Age 40--75 years,
- **and** iron deficiency anemia (several lab tests),
- **and** no other cause, terminal illness, *etc.,*
- **and** no follow-up (colonoscopy) performed in reasonable time.

[^trigExample]: Murphy *et al. BMJ Qual Saf.* 2014;23(1):8.


## Diagnostic electronic triggers: helpful but imperfect

- Tend to low predictive values: 50--70%,[^trigExample] or sometimes
  lower (9--16%),[^primary] depending on the trigger design. In other
  words, not all trigger-positive cases are true errors.

[^primary]: Singh *et al. Arch Intern Med.* 2007;167(3):302--308.

- Built from *a priori* rules, so they may miss cases of error, too.

- Manual chart review is time-consuming and not scalable.


## Objectives

![paper title](img/papertitle.png)\

Hypothesis:
: We can improve e-trigger performance (identifying MODs) by
considering multiple additional EHR variables, moving beyond manually
designed rules.

- Goal: emulate human reviewers at larger scale. Detect possible
missed opportunities in diagnosis **afterwards.** Not **predicting**
in the ED!


# Methods

## Study design: overview

- Retrospective cohort analysis using VA national EHR (>20M
  patients)

- Two high-risk ED cohorts identified by rules-based e-triggers. These
  rules were developed by an expert panel.[^Vaghani]

[^Vaghani]: Vaghani *et al. JAMA Intern Med.* 2025;185(2):143--151.

- Expert clinician review provided criterion labels (MOD vs.\ no MOD)
  using standardized instrument developed from prior work (the Revised
  Safer Dx Instrument).[^revised]

[^revised]: Singh *et al. Diagnosis.* 2019;6(4):315--323.

- Machine learning models trained and tested on structured EHR
  variables

- Flow: EHR $\to$ e-trigger $\to$ reviewer. "Two-stage filter."


## E-trigger 1: dizziness + stroke risk factors

- Inclusion: ED visits for dizziness/vertigo + stroke risk factors

- Outcome: hospitalization for stroke or TIA within 30 days after ED
  discharge

- Timeframe: 2016--2020


## E-trigger 2: abdominal pain + vitals

- Inclusion: ED visits for abdominal pain + abnormal temperature

- Outcome: hospitalization within 10 days after ED discharge

- Examples of missed diagnoses: cholangitis, cholecystitis, infectious
  colitis


## Data sources & labeling

- Data: Structured EHR from index ED visit and subsequent hospital
  data

- Random sample of trigger-positive records reviewed by trained
  clinicians using standardized instrument

- Labeled records split into training and test sets


## Structured EHR variables for ML

- Dizziness model: 148 candidate variables

- Abdominal pain model: 153 candidate variables

- Types: demographics, vitals, labs, orders (imaging and
  consultations), visit times, risk factors (past diagnoses). Details
  in eTable 1 from paper Supplement,[^mainPaper] or in code.[^mainGH]

[^mainPaper]: Zimolzak *et al. JAMA Netw Open.* 2024;7(9):e2431982.

[^mainGH]: github.com/zimolzak/ml-detect-diagnostic-safety

- Preselection via bivariate tests (t-test or $\chi^2$), $P < 0.10$.


## ML features selected

18 and 31 variables (dizziness and abdominal pain, respectively)
remained in final models.

- ED duration
- Time from ED to inpatient admission
- HR, BP, RR, pain, temperature (min, max, count, first; for ED and inpatient)
- Ethnicity
- CT scan ordered (yes/no)
- CT scan abnormal (yes/no)
- WBC, glucose, potassium, chloride, amylase
- Prior ICD code cholecystitis, or cerebral aneurysm


## Machine learning methods

- Algorithms: regularized logistic regression and random forest

- Random forest with limited tree depth to reduce overfitting

- Tools: Python 3.7.4; `scipy`, `numpy`, `scikit-learn`

- Performance metrics: positive predictive value (PPV) with 95% Wald
  CI


# Results

## Label counts: dizziness cohort

- Rules-based flagged: 82 reviewed records

- Reviewer-identified MODs: 39/82 (PPV **48%**; 95% CI 37--58)


## ML results: dizziness cohort

Best ML (random forest) performance:

- Correctly identified 36/39 true MODs
  
- Correctly identified 40/43 negatives
  
- PPV **92%** (95% CI 84--100)


## Label counts: abdominal pain cohort

- Rules-based flagged: 104 reviewed records

- Reviewer-identified MODs: 31/104 (PPV **30%**; 95% CI 21--39)


## ML results: abdominal pain cohort

- ML correctly identified 26/31 true MODs and 71/73 negatives

- PPV **93%** (95% CI 83--100)


## Comparative table: rules vs.\ ML (summary)

E-trigger            | True+/Total | PPV (CI)
---------------------|:-----------:|---------
**Dizziness**                | |
\quad{} Rules-based positive for MOD | 39/82  | **48%** (37--58)
\quad{} ML positive for MOD          | 36/39  | **92%** (84--100)
\quad{} ML negative for MOD          | 3/43   | NA
**Abdominal pain**           | |
\quad{} Rules-based positive for MOD | 31/104 | **30%** (21--39)
\quad{} ML positive for MOD          | 26/28  | **93%** (83--100)
\quad{} ML negative for MOD          | 5/76   | NA


## Example study flow diagram

![study flow](img/studyflow-crop.png)\


# Conclusions

## Interpretation: key findings

- ML substantially increased PPV of e-triggers for both cohorts.

- ML models approximated clinician labels with high accuracy.

- Enables more efficient, scalable monitoring of diagnostic errors


## Practical implications

Health systems can use ML-enhanced e-triggers to:

- Prioritize cases for chart review

- Monitor diagnostic safety at scale

- Support quality improvement and research: **learn** from missed
  opportunities and apply **improvement** strategies.


## Future directions

- Incorporate clinical note text (NLP) to capture richer signals

- Increase expert-labeled training set size

- Validate models in external, independent populations

- Explore implementation workflows for real-time monitoring.
  (Remember: *not* a point-of-care alert or ED decision support)


## Takeaway/Conclusions

- ML can improve the positive predictive value of rules-based
  e-triggers for detecting missed diagnostic opportunities.

- Offers scalable approach to identify diagnostic errors and reduce
  manual review burden

- Promising tool for research and quality improvement, pending broader
  validation


## Acknowledgments

Agency for Healthcare Research and Quality: **R01 HS027363**

Partly supported by:

- Houston VA HSR&D CIN 13-413
- VA National Center for Patient Safety
- AHRQ R01 HS028595
- AHRQ R18 HS029347

Andrew Zimolzak, **Li Wei, Usman Mir, Ashish Gupta, Viral Vaghani,
Devika Subramanian,[^students] Hardeep Singh.** Machine Learning to
Enhance Electronic Detection of Diagnostic Errors. *JAMA Netw Open.*
2024;7(9):e2431982. Published 2024 Sep 3.
doi:10.1001/jamanetworkopen.2024.31982

[^students]: with Adel Hassan, Max Yu, Angela Wu, Justin Mower


# Additional informatics aspects

## Limitations

- Time/resource cost to prepare structured variables: **feature
  engineering.**[^engineer] We also *deliberately chose* which
  features to prepare, based on clinical knowledge.

[^engineer]: Pedro Domingos. *Commun.\ ACM* 55(10) October 2012:
78--87. doi:10.1145/2347736.2347755

- Small number of expert-labeled records limits model learning and
  test precision. (Time/resource cost again)

- Models used only structured data: may miss signals in clinical notes.

- Single-system (VA) data; requires external validation.


## Technical challenges

Air-gapped research analysis environment: no Internet.

- VA is mostly familiar with SQL $\to$ SAS workflow for analysis
- No usual ML toolkits available out of the box
- Apply for "development workspace"
- Manual upload of Anaconda/Python packages (March 2020)

This was before Melax Tech (as far as I know!)


## Techincal: source control

- Source code control, preservation, reproducibility: learned a lot about `git-bundle`!

- Meticulous review for sensitive information in `ipynb` files. Is there an opportunity for a Python package?


## Techincal: source control

- **Example** if you want to avoid sensitive data in your Jupyter output cells:

```python
# Hard to remember each time:
print(patient_lab_results.loc[
    :,
    patient_lab_results.columns != ‘PatientSSN’
])

# What if this just worked?
print(patient_lab_results)
```

- **But beware** identifiers *in the code itself* (not outputs):

```sql
SELECT * FROM LAB_RESULTS WHERE PatientSSN = 123456789
```


## Technical challenges

- Multiple "hops" to log on remotely (especially important during pandemic)

- Limited hardware capabilities. This is evolving, but additional access request is/was needed for different hardware environment.


## Thank you! and "See also"

My current/past informatics efforts at BCM and elsewhere:

- Epic Cosmos efforts[^cosmos]
- Clinical/translational science: www.ctph-texas.org
- Datathon efforts[^datathon]
- Phenotype reusability[^cipher]^,^[^portable]
- ML for phenotyping[^nate]^,^[^justine]

[^nate]: Stud Health Technol Inform. 2019;264:133-137.

[^justine]: JCO Clin Cancer Inform. 2020;4:749-756.

[^cosmos]: J Am Med Inform Assoc. 2025;32(1):227--229.

[^cipher]: J Am Med Inform Assoc. 2024;31(5):1126-1134.

[^portable]: BMJ Health Care Inform. 2022;29(1):e100565.

[^datathon]: J Clin Transl Sci. 2022;6(1):e125.


**zimolzak@bcm.edu**

Source for this talk: github.com/zimolzak/ml-detect-dx-error-seminar
